{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_approach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network approach with RNN"
      ],
      "metadata": {
        "id": "xmeGQdA-6OD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and data import"
      ],
      "metadata": {
        "id": "3Gis6jeY6V-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy.data import Field, Dataset, Example\n",
        "\n",
        "import random\n",
        "\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJt0lhH6lwNC",
        "outputId": "72ab1ee8-c570-4412-975e-23593ddd551a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KElhBiVmaaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34162103-5dea-4010-cf9e-c8a65152fd7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#import of the processed dataset and the columns' names\n",
        "from_drive = True\n",
        "dataset = dict()\n",
        "path = \"/content/gdrive/MyDrive/Magistrale/Stage/data\"\n",
        "\n",
        "if from_drive == True: \n",
        "  drive.mount(\"/content/gdrive\")\n",
        "  dataset[\"ace\"] = pd.read_csv(path + \"/preprocessed_ace2.csv\")\n",
        "  dataset[\"copd\"] = pd.read_csv(path + \"/preprocessed_copd2.csv\")\n",
        "  dataset[\"ppi\"] = pd.read_csv(path + \"/preprocessed_ppi2.csv\")\n",
        "else: \n",
        "  dataset[\"ace\"] = pd.read_csv(path + \"/content/preprocessed_ace2.csv\")\n",
        "  dataset[\"copd\"] = pd.read_csv(path + \"/content/preprocessed_copd2.csv\")\n",
        "  dataset[\"ppi\"] = pd.read_csv(path + \"/content/preprocessed_ppi2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN5V1D64Sgk-"
      },
      "source": [
        "## Preparing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN2jlmwWSgk-"
      },
      "outputs": [],
      "source": [
        "#random seed for reproducibility\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "#FIELD: how the data should be processed\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'label' : LABEL, \"text\" : TEXT}\n",
        "\n",
        "#HYPERPARAMETERS\n",
        "\n",
        "#dataset configuration\n",
        "i = \"ace\" #which dataset\n",
        "clean_text = True #otherwise, it will be used \"text\"\n",
        "\n",
        "#bucket iterator configuration\n",
        "BATCH_SIZE = 64 \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#neural network configuration\n",
        "EMBEDDING_DIM = 100 #size of the dense word vectors (usually 50-250)\n",
        "HIDDEN_DIM = 256 #size of the hidden states (usually 100-500)\n",
        "OUTPUT_DIM = 1 #number of classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removal and renaming of columns\n",
        "\n",
        "if clean_text == True: \n",
        "  dataset[i].drop(dataset[i].columns.difference(['Label', \"text_clean\"]), 1, inplace=True)\n",
        "  dataset[i].rename(columns={'text_clean': 'text'}, inplace=True)\n",
        "\n",
        "else: \n",
        "  dataset[i].drop(dataset[i].columns.difference(['Label', \"text\"]), 1, inplace=True)\n",
        "\n",
        "dataset[i].rename(columns={'Label': 'label'}, inplace=True)\n",
        "\n",
        "#final dataset with \"label\" and \"text\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J-7rOPxqDBa",
        "outputId": "2d3b9de0-b0be-48e4-84f5-82465557bc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[i].shape)\n",
        "dataset[i].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ZYgYEQFCqu3P",
        "outputId": "069a52fd-8085-4f73-9024-9c1105ab9fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2496, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  distinct and combined vascular effects of ace ...\n",
              "1      0  computerized surveillance of adverse drug reac...\n",
              "2      0  glomerular size selective dysfunction in niddm...\n",
              "3      0  total arterial compliance in ambulatory hypert...\n",
              "4      0  racial differences in the outcome of left vent..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f356bf56-160f-4adc-be8e-a66ba32005a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>distinct and combined vascular effects of ace ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>computerized surveillance of adverse drug reac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>glomerular size selective dysfunction in niddm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>total arterial compliance in ambulatory hypert...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>racial differences in the outcome of left vent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f356bf56-160f-4adc-be8e-a66ba32005a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f356bf56-160f-4adc-be8e-a66ba32005a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f356bf56-160f-4adc-be8e-a66ba32005a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataFrameDataset(Dataset):\n",
        "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
        "    def __init__(self, examples, fields, filter_pred=None):\n",
        "        \"\"\"\n",
        "        Create a dataset from a pandas dataframe of examples and Fields\n",
        "        Arguments:\n",
        "            examples pd.DataFrame: DataFrame of examples\n",
        "            fields {str: Field}: The Fields to use in this tuple. The\n",
        "                string is a field name, and the Field is the associated field.\n",
        "            filter_pred (callable or None): use only exanples for which\n",
        "                filter_pred(example) is true, or use all examples if None.\n",
        "                Default is None\n",
        "        \"\"\"\n",
        "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
        "        if filter_pred is not None:\n",
        "            self.examples = filter(filter_pred, self.examples)\n",
        "        self.fields = dict(fields)\n",
        "        # Unpack field tuples\n",
        "        for n, f in list(self.fields.items()):\n",
        "            if isinstance(n, tuple):\n",
        "                self.fields.update(zip(n, f))\n",
        "                del self.fields[n]\n",
        "\n",
        "class SeriesExample(Example):\n",
        "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
        "  \n",
        "    @classmethod\n",
        "    def fromSeries(cls, data, fields):\n",
        "        return cls.fromdict(data.to_dict(), fields)\n",
        "\n",
        "    @classmethod\n",
        "    def fromdict(cls, data, fields):\n",
        "        ex = cls()\n",
        "        \n",
        "        for key, field in fields.items():\n",
        "            if key not in data:\n",
        "                raise ValueError(\"Specified key {} was not found in \"\n",
        "                \"the input data\".format(key))\n",
        "            if field is not None:\n",
        "                setattr(ex, key, field.preprocess(data[key]))\n",
        "            else:\n",
        "                setattr(ex, key, data[key])\n",
        "        return ex"
      ],
      "metadata": {
        "id": "q55Zvmn6rkeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch dataset \n",
        "df = DataFrameDataset(dataset[i], fields)"
      ],
      "metadata": {
        "id": "oBNm2G54sE1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train, test and val split"
      ],
      "metadata": {
        "id": "nFBCeSvk9cOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train and test split\n",
        "train_data, test_data = df.split(split_ratio=0.8, stratified=True, strata_field='label', random_state = random.seed(SEED))\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "\n",
        "#checking an example\n",
        "print(vars(\"\\n\", train_data.examples[0]))"
      ],
      "metadata": {
        "id": "SAXH6fKpsSxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb6Ka2hFSglD"
      },
      "outputs": [],
      "source": [
        "#train and val split\n",
        "train_data, valid_data = train_data.split(split_ratio=0.8, stratified=True, strata_field='label', random_state = random.seed(SEED))\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VOCABULARY: look up table where every unique word in your data set has a corresponding _index_ (an integer).\n",
        "#each _index_ is used to construct a _one-hot_ vector for each word.\n",
        "TEXT.build_vocab(train_data) #optional parameter: max_size = MAX_VOCAB_SIZE\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "JwLWNx53uWm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahSv1rMYSglF"
      },
      "source": [
        "Only build the vocabulary on the training set because when testing a machine learning system you do not want to look at the test set in any way. Also, do not include the validation set as you want it to reflect the test set as much as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB-wqYIqSglF",
        "outputId": "c646e348-21b4-49f2-fb59-afaef87b5a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 11152\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3X2HdQOSglF"
      },
      "source": [
        "There is the addition of the `<pad>` token.\n",
        "\n",
        "When feeding sentences into our model, you feed a _batch_ of them at a time, i.e. more than one at a time, and all sentences in the batch need to be the same size. Thus, to ensure each sentence in the batch is the same size, any shorter than the longest within the batch are padded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDu0mHTiSglF",
        "outputId": "8437d514-47a9-4101-a838-2ba1ab0f1fb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 14847), ('of', 13867), ('and', 12581), ('in', 11351), ('with', 7105), ('to', 6979), ('patients', 5788), ('a', 5301), ('drug', 4476), ('0', 4106), ('effects', 3924), ('use', 3730), ('was', 3666), ('blood', 3643), ('therapeutic', 3491), ('were', 3414), ('therapy', 3130), ('1', 2926), ('treatment', 2891), ('or', 2817)]\n"
          ]
        }
      ],
      "source": [
        "print(\"Most common words:\", TEXT.vocab.freqs.most_common(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRZihaahSglG"
      },
      "outputs": [],
      "source": [
        "#see the vocabulary directly using either stoi (string to int) or itos (int to string)\n",
        "print(TEXT.vocab.itos[:10])\n",
        "\n",
        "#check the labels, ensuring 0 is for negative and 1 is for positive\n",
        "print(LABEL.vocab.stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZdKy_vJSglH"
      },
      "outputs": [],
      "source": [
        "#creating the iterators\n",
        "\n",
        "#ITERATORS: you iterate over iterators in the training/evaluation loop, \n",
        "#and they return a batch of examples (indexed and converted into tensors) at each iteration.\n",
        "\n",
        "#BUCKET ITERATORS: special type of iterator that will return a batch of examples \n",
        "#where each example is of a similar length, minimizing the amount of padding per example.\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device, \n",
        "    sort = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyyTrXY1SglH"
      },
      "source": [
        "## Build the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All layers have their parameters initialized to random values, unless explicitly specified.\n",
        "\n",
        "- **Embedding layer**: is used to transform the sparse one-hot vector into a dense embedding vector (dense as the dimensionality is a lot smaller and all the elements are real numbers). It is simply a single fully connected layer. \n",
        "As well as reducing the dimensionality of the input to the RNN, there is the theory that words with similar meaning are mapped close together in this dense vector space.\n",
        "\n",
        "- **RNN**: takes in the dense vector and the previous hidden state $h_{t-1}$, which it uses to calculate the next hidden state, $h_t$.\n",
        "\n",
        "- **Linear layer**: takes the final hidden state and feeds it through a fully connected layer, $f(h_T)$, transforming it to the correct output dimension."
      ],
      "metadata": {
        "id": "5OT9rn6chJoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IHPGjaToSglH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module): #the RNN class is a sub-class of nn.Module\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim): #define the layers of the module \n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim) #embedding layer\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim) #rnn\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim) #linear layer\n",
        "        \n",
        "    def forward(self, text): #called when feeding examples into the model\n",
        "\n",
        "        #text = [sent len, batch size] (tensor)\n",
        "        #text is a batch of senteces, each having each word converted into a one-hot vector \n",
        "\n",
        "        #the input batch is passed through the embedding layer to get `embedded`, \n",
        "        #which gives us a dense vector representation of our sentences.\n",
        "        embedded = self.embedding(text) \n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim] (tensor)\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim] (tensor)\n",
        "        #output is the concatenation of the hidden state from every time step\n",
        "\n",
        "        #hidden = [1, batch size, hid dim] (tensor)\n",
        "        #hidden is simply the final hidden state\n",
        "        \n",
        "        #assert statement udse to verify if output is the concatenation of the \n",
        "        #hidden state from every time step and hidden is the final hidden state\n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        #squeeze is used to remove a dimension of size 1\n",
        "        \n",
        "        #the last hidden state, hidden, is fed through the linear layer to produce a prediction\n",
        "        return self.fc(hidden.squeeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tensor `text` should have another dimension due to the one-hot vectors, however PyTorch conveniently stores a one-hot vector as it's index value, i.e. the tensor representing a sentence is just a tensor of the indexes for each token in that sentence. The act of converting a list of tokens into a list of indexes is commonly called *numericalizing*."
      ],
      "metadata": {
        "id": "86qw7_FL1We-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kfAMS75SglI"
      },
      "outputs": [],
      "source": [
        "#create an instance of the RNN class\n",
        "INPUT_DIM = len(TEXT.vocab) #input dimension: dimension of the one-hot vectors (equal to the vocabulary size)\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Input dimension**: dimension of the one-hot vectors (equal to the vocabulary size).\n",
        "- **Embedding dimension**: size of the dense word vectors. This is usually around 50-250 dimensions, but depends on the size of the vocabulary.\n",
        "- **Hidden dimension**: size of the hidden states. This is usually around 100-500 dimensions, but also depends on factors such as on the vocabulary size, the size of the dense vectors and the complexity of the task.\n",
        "- **Output dimension**: usually the number of classes. However in the case of only 2 classes the output value is between 0 and 1 and thus can be 1-dimensional, i.e. a single scalar real number."
      ],
      "metadata": {
        "id": "ugyYN3_68Wy1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npsTUoyLSglI",
        "outputId": "92909701-32c3-4fe5-b0e4-7dddf29fa616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 1,207,105 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "  \"\"\" \n",
        "  Function that tells how many trainable parameters the model has \n",
        "  so we can compare the number of parameters across different models.\n",
        "  \"\"\"\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT3Ge5clSglI"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQnHgPY2SglI"
      },
      "outputs": [],
      "source": [
        "#OPTIMIZER: algorithm we use to update the parameters of the module. \n",
        "#chosen optimizer: stochastic gradient descent_ (SGD) \n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "#CRITERION: loss function\n",
        "#chosen loss function: binary cross entropy with logits\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#place the model and the criterion on the GPU (if we have one)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLARuz6DSglJ"
      },
      "source": [
        "The model currently outputs an unbound real number. As the labels are either 0 or 1, you want to restrict the predictions to a number between 0 and 1. This can be done using the _sigmoid_ or _logit_ functions. \n",
        "\n",
        "Is it possible to use the bound scalar to calculate the loss using binary cross entropy. \n",
        "\n",
        "The `BCEWithLogitsLoss` criterion carries out both the sigmoid and the binary cross entropy steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqNS2ij9SglJ"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "  \n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #feed the prediction through a sigmoid layer, squashing the values in [0, 1], then round them to the nearest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds)) \n",
        "\n",
        "    #calculate how many rounded predictions equal the actual labels and average it across the batch\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoFsXtwZSglK"
      },
      "source": [
        "The loss and accuracy is accumulated across the epoch, the `.item()` method is used to extract a scalar from a tensor which only contains a single value.\n",
        "\n",
        "Finally, we return the loss and accuracy, averaged across the epoch. The `len` of an iterator is the number of batches in the iterator.\n",
        "\n",
        "You may recall when initializing the `LABEL` field, we set `dtype=torch.float`. This is because TorchText sets tensors to be `LongTensor`s by default, however our criterion expects both inputs to be `FloatTensor`s. Setting the `dtype` to be `torch.float`, did this for us. The alternative method of doing this would be to do the conversion inside the `train` function by passing `batch.label.float()` instad of `batch.label` to the criterion. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w6ssTjdJSglK"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion): #iterates over all examples, one batch at a time\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train() #put the model in \"training mode\", which turns on dropout and batch normalization\n",
        "    #although we aren't using them in this model, it's good practice to include it\n",
        "    \n",
        "    for batch in iterator: #for each batch\n",
        "        \n",
        "        optimizer.zero_grad() #we first zero the gradients\n",
        "\n",
        "        #feed the batch of sentences, batch.text, into the model \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        #squeeze is needed as the predictions are initially size [batch size, 1]\n",
        "        #and we need to remove the dimension of size 1, as PyTorch expects the \n",
        "        #predictions input to our criterion function to be of size [batch size]        \n",
        "        \n",
        "\n",
        "        #computation of loss \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        #computation of accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        #loss and accuracy are then calculated using the predictions and the labels, batch.label, \n",
        "        #with the loss being averaged over all examples in the batch.\n",
        "\n",
        "        loss.backward() #calculate the gradient of each parameter\n",
        "        \n",
        "        optimizer.step() #update the parameters using the gradients and optimizer algorithm\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each parameter in a model has a `grad` attribute which stores the gradient calculated by the `criterion`. PyTorch does not automatically remove (or \"zero\") the gradients calculated from the last gradient calculation, so they must be manually zeroed."
      ],
      "metadata": {
        "id": "lD8ct0MgJuJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, you do not need to do `model.forward(batch.text)`, simply calling the model works."
      ],
      "metadata": {
        "id": "ZYmVOPymKlAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nqNe-ONfKkms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cktTGJzgSglK"
      },
      "source": [
        "`evaluate` is similar to `train`, with a few modifications as you don't want to update the parameters when evaluating.\n",
        "\n",
        "`model.eval()` puts the model in \"evaluation mode\", this turns off _dropout_ and _batch normalization_. Again, we are not using them in this model, but it is good practice to include them.\n",
        "\n",
        "No gradients are calculated on PyTorch operations inside the `with no_grad()` block. This causes less memory to be used and speeds up computation.\n",
        "\n",
        "The rest of the function is the same as `train`, with the removal of `optimizer.zero_grad()`, `loss.backward()` and `optimizer.step()`, as we do not update the model's parameters when evaluating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAeXTaJ9SglK"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4szT0UiSglK"
      },
      "source": [
        "We'll also create a function to tell us how long an epoch takes to compare training times between models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8g23ObuSglK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewPdSicySglK"
      },
      "source": [
        "We then train the model through multiple epochs, an epoch being a complete pass through all examples in the training and validation sets.\n",
        "\n",
        "At each epoch, if the validation loss is the best we have seen so far, we'll save the parameters of the model and then after training has finished we'll use that model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84EKqVeCSglK",
        "outputId": "1a324ef9-5e2b-44c0-dd29-b14c56d3fe30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.520 | Train Acc: 97.31%\n",
            "\t Val. Loss: 0.433 |  Val. Acc: 92.66%\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.332 | Train Acc: 97.81%\n",
            "\t Val. Loss: 0.333 |  Val. Acc: 92.66%\n",
            "Epoch: 03 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.243 | Train Acc: 97.68%\n",
            "\t Val. Loss: 0.286 |  Val. Acc: 92.66%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.195 | Train Acc: 97.69%\n",
            "\t Val. Loss: 0.261 |  Val. Acc: 92.89%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.166 | Train Acc: 97.87%\n",
            "\t Val. Loss: 0.248 |  Val. Acc: 92.89%\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK7U_z67SglL"
      },
      "source": [
        "You may have noticed the loss is not really decreasing and the accuracy is poor. This is due to several issues with the model which we'll improve in the next notebook.\n",
        "\n",
        "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-JFRDmdSglL",
        "outputId": "346d4228-aced-43bc-8d82-bc8418646551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.159 | Test Acc: 97.70%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    }
  ]
}
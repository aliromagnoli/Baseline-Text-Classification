{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Methods.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wFfxgyu93gs1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file contains methods for the \"Data Import\" file. \n",
        "In order to be correctly used, this file needs to be inside a Drive folder with the .py extension."
      ],
      "metadata": {
        "id": "_8KA2PzS3XQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VwBRs6ecd2iO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Import"
      ],
      "metadata": {
        "id": "wFfxgyu93gs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import of data"
      ],
      "metadata": {
        "id": "32vP_rulorQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_value_counts(l, df): \n",
        "  \"\"\"\n",
        "  Given a list of column names \"l\" and a dataset \"df\", \n",
        "  it prints the value counts for each specified variable.\n",
        "  \"\"\"\n",
        "  for item in l: \n",
        "    print(df[item].value_counts(), \"\\n\")\n",
        "\n",
        "\n",
        "def rename_columns(names, df): \n",
        "  \"\"\"\n",
        "  Given a dictionary \"names\" like {\"old_name\" : \"new_name\"} and a dataset \"df\", \n",
        "  it renames the column names specified as \"old_name\" with new names specified as \"new_name\".\n",
        "  \"\"\"\n",
        "  for key in names: \n",
        "    df.rename(columns={key : names[key]}, inplace=True)"
      ],
      "metadata": {
        "id": "Zwt3eYrhovC1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column preprocessing"
      ],
      "metadata": {
        "id": "g607gfULov8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Text preprocessing"
      ],
      "metadata": {
        "id": "WmRCkyKupBL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def listToString(s): \n",
        "  \"\"\"\n",
        "  Given a list \"s\", it returns \"s\" as a string.\n",
        "  \"\"\"\n",
        "  str1 = \"\" \n",
        "  for ele in s: \n",
        "      str1 = str1 + \" \" + ele\n",
        "  return str1\n",
        "\n",
        "\n",
        "def split_on_word(text):\n",
        "  \"\"\"\n",
        "  Given a list or string \"text\", it uses a regular expression tokenizer \n",
        "  (that keeps apostrophes) to return a tokenized list of lists \n",
        "  (one list for each sentence: [[word, word], [word, word, ..., word], ...]).\n",
        "  \"\"\"\n",
        "  if type(text) is list:\n",
        "      return [regexp_tokenize(sentence, pattern=\"\\w+(?:[-']\\w+)*\") for sentence in text]\n",
        "  else:\n",
        "      return regexp_tokenize(text, pattern=\"\\w+(?:[-']\\w+)*\")\n",
        "\n",
        "\n",
        "def count_words(df, column):\n",
        "  \"\"\"\n",
        "  Given a dataset \"df\" and a column name \"column\", \n",
        "  it returns the dataset \"df\" with a new column containing the number of words in \"column\".\n",
        "  \"\"\"\n",
        "  df = df.copy()\n",
        "  col_name = \"n_words_in_\" + column\n",
        "  df[col_name] = df[column].apply(lambda x: len(split_on_word(x)))\n",
        "  return df\n",
        "\n",
        "\n",
        "def clean_text(df, col):\n",
        "  \"\"\"\n",
        "  Given a dataset \"df\" and a column name \"col\", \n",
        "  it modifies the column \"col\", keeping only alpha-numeric characters and \n",
        "  replacing all white space with a single space, and then return \"df\"\n",
        "  \"\"\"\n",
        "  df = df.copy()\n",
        "  \n",
        "  #[^A-Za-z0-9]+: regex to match a string of characters that are not a letters or numbers\n",
        "  return df[col].apply(lambda x: re.sub('[^A-Za-z0-9]+', ' ', str(x).lower()))\\\n",
        "                .apply(lambda x: re.sub('\\s+', ' ', x).strip())"
      ],
      "metadata": {
        "id": "nWmdWgz0o3Nw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Features preprocessing"
      ],
      "metadata": {
        "id": "a4EoPtF6o4d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iVly4HevTQFE"
      },
      "outputs": [],
      "source": [
        "def from_list_of_values_to_columns(col, df, print=False): \n",
        "  \"\"\"\n",
        "  Given a column name \"col\" and a dataset \"df\", \n",
        "  it converts a column containing lists of values to a binary column for each value.\n",
        "  \"\"\"\n",
        "  df = df.copy()\n",
        "\n",
        "  #obtaining the unique values \n",
        "\n",
        "  df[col] = df[col].apply(eval)\n",
        "\n",
        "  col_dict = {} \n",
        "  for i in df[col]: #obtain value_count in a dictionary\n",
        "    for j in i:\n",
        "        if j not in col_dict:\n",
        "            col_dict[j] = 1 #new column\n",
        "        else:\n",
        "            col_dict[j] += 1 #update column count\n",
        "\n",
        "  series = pd.Series([x for _list in df[col] for x in _list]) #reducing its dimensions from 2 to 1 \n",
        "\n",
        "  if print == True:\n",
        "    print(series.value_counts()) #display value count\n",
        "\n",
        "  #creating new binary columns \n",
        "\n",
        "  bool_dict = {} #create boolean dict (the binary value for every colum in col_dict and for every row in the df)\n",
        "  for i, item in enumerate(col_dict.keys()): \n",
        "    bool_dict[item] = df[col].apply(lambda x: item in x)\n",
        "\n",
        "  return pd.DataFrame(bool_dict).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update `col_names`"
      ],
      "metadata": {
        "id": "J_aLvAs3vDcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_col_names(col_names, col, name_df, sub_features): \n",
        "  \"\"\"\n",
        "  Given a dataset to update \"col_names\", a column name \"col\", \n",
        "  a dataset name \"name_df\" and a list of values \"sub_features\", \n",
        "  it update the dataset \"col_names\" with \"sub_features\"\n",
        "  \"\"\"\n",
        "\n",
        "  #useful trasnformation for assigning a list to a dataframe cell\n",
        "  l = col_names.index[col_names[\"feature\"] == col].tolist()\n",
        "  col_names.at[l[0], name_df] = sub_features\n",
        "\n",
        "  return col_names"
      ],
      "metadata": {
        "id": "cvldLC1QfMLc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topic search"
      ],
      "metadata": {
        "id": "PpeCbvArr6Xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_documents_about_topic(df, column, new_column, l): \n",
        "  \"\"\"\n",
        "  Given a dataset \"df\", a column name \"column\", a new column name \"new_column\" and a list of strings \"l\", \n",
        "  it modifies \"df\" adding a binary column that specify for every row if \"column\" contains at least 1 of the strings in \"l\".\n",
        "  \"\"\"\n",
        "\n",
        "  x = df[column][df[column].str.contains('|'.join(l))] #rows in df[column] that contains at least 1 item of \"l\"\n",
        "  \n",
        "  df[new_column] = 0\n",
        "  df.loc[df.index.isin(x.index), new_column] = 1 #assigning 1 to the corresponding rows of x in df\n",
        "\n",
        "  print(\"Number of documents that\", new_column, \":\", len(x))\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "JnNHB3Kqr7_m"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}